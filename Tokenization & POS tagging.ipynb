{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pai-Ya-Ting/Text-mining/blob/main/Tokenization%20%26%20POS%20tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay_sD_IbWnjY"
      },
      "source": [
        "1. Tokenization & POS tagging (45%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsOXz8bAWi6w"
      },
      "source": [
        "(a) Read 3 document (doc1.txt, doc2.txt, doc3.txt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlI0kQFzWDt1"
      },
      "source": [
        "def read_data(filename):\n",
        "  return open(filename).read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cg914r3aQtu"
      },
      "source": [
        "doc1_text, doc2_text, doc3_text = read_data(\"doc1.txt\"), read_data(\"doc2.txt\"), read_data(\"doc3.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAHQK_h-Wxxx"
      },
      "source": [
        "(b) Normalize words: convert all upper-case letter to lower case (for example 'Word' and 'word' are considered as the same word)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ndgNZMwWMJB"
      },
      "source": [
        "doc1_text_n, doc2_text_n, doc3_text_n = doc1_text.lower(), doc2_text.lower(), doc3_text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUj9HunyWysg"
      },
      "source": [
        "(c)Tokenization for all 3 documents: (Feel free to use any tokenization method from any package, such as nltk, spacy...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiQGCGiIW1wF",
        "outputId": "45f885fe-27cb-4abd-ff3d-0ae9a0a33ff6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "doc1_tokens = nltk.word_tokenize(doc1_text_n)\n",
        "doc2_tokens = nltk.word_tokenize(doc2_text_n)\n",
        "doc3_tokens = nltk.word_tokenize(doc3_text_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqoqPVTp4MEh",
        "outputId": "98a3e6a0-1867-400f-9f85-5b8a2157b552"
      },
      "source": [
        "print(doc1_tokens)\n",
        "print(doc2_tokens)\n",
        "print(doc3_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['to', 'get', 'started', ',', 'the', 'python', 'sections', 'are', 'linked', 'at', 'the', 'left', '--', 'python', 'set', 'up', 'to', 'get', 'python', 'installed', 'on', 'your', 'machine', ',', 'python', 'introduction', 'for', 'an', 'introduction', 'to', 'the', 'language', ',', 'and', 'then', 'python', 'strings', 'starts', 'the', 'coding', 'material', ',', 'leading', 'to', 'the', 'first', 'exercise', '.', 'the', 'end', 'of', 'each', 'written', 'section', 'includes', 'a', 'link', 'to', 'the', 'code', 'exercise', 'for', 'that', 'section', \"'s\", 'material', '.', 'the', 'lecture', 'videos', 'parallel', 'the', 'written', 'materials', ',', 'introducing', 'python', ',', 'then', 'strings', ',', 'then', 'first', 'exercises', ',', 'and', 'so', 'on', '.', 'at', 'google', ',', 'all', 'this', 'material', 'makes', 'up', 'an', 'intensive', '2-day', 'class', ',', 'so', 'the', 'videos', 'are', 'organized', 'as', 'the', 'day-1', 'and', 'day-2', 'sections', '.', 'this', 'material', 'was', 'created', 'by', 'nick', 'parlante', 'working', 'in', 'the', 'engedu', 'group', 'at', 'google', '.', 'special', 'thanks', 'for', 'the', 'help', 'from', 'my', 'google', 'colleagues', 'john', 'cox', ',', 'steve', 'glassman', ',', 'piotr', 'kaminksi', ',', 'and', 'antoine', 'picard', '.', 'and', 'finally', 'thanks', 'to', 'google', 'and', 'my', 'director', 'maggie', 'johnson', 'for', 'the', 'enlightened', 'generosity', 'to', 'put', 'these', 'materials', 'out', 'on', 'the', 'internet', 'for', 'free', 'under', 'the', 'creative', 'commons', 'attribution', '2.5', 'license', '--', 'share', 'and', 'enjoy', '!']\n",
            "['welcome', 'to', 'google', \"'s\", 'python', 'online', 'tutorial', '.', 'it', 'is', 'based', 'on', 'the', 'introductory', 'python', 'course', 'offered', 'internally', '.', 'originally', 'created', 'during', 'the', 'python', '2.4', 'days', ',', 'we', \"'ve\", 'tried', 'to', 'keep', 'the', 'content', 'universal', 'and', 'exercises', 'relevant', ',', 'even', 'for', 'newer', 'releases', '.', 'as', 'mentioned', 'on', 'the', 'setup', 'page', ',', 'this', 'material', 'covers', 'python', '.', 'while', 'we', 'recommend', '``', 'avoiding', \"''\", 'python', 'for', 'now', ',', 'recognize', 'that', 'it', 'is', 'the', 'future', ',', 'as', 'all', 'new', 'features', 'are', 'only', 'going', 'there', '.', 'the', 'good', 'news', 'is', 'that', 'developers', 'learning', 'either', 'version', 'can', 'pick', 'up', 'the', 'other', 'without', 'too', 'much', 'difficulty', '.', 'if', 'you', 'want', 'to', 'know', 'more', 'about', 'choosing', 'python', ',', 'check', 'out', 'this', 'post', '.', \"''\"]\n",
            "['if', 'you', 'need', 'a', 'quick', 'brush-up', ',', 'or', 'learning', 'python', 'for', 'the', 'first', 'time', ',', 'you', \"'ve\", 'come', 'to', 'the', 'right', 'place', '!', 'let', \"'s\", 'get', 'started', 'learning', 'one', 'of', 'the', 'most', 'easiest', 'coding', 'languages', 'out', 'there', 'right', 'now', '.', 'there', \"'s\", 'no', 'need', 'to', 'fret', 'if', 'you', 'have', \"n't\", 'coded', 'before', '.', 'by', 'the', 'time', 'you', 'finish', 'this', 'course', ',', 'you', \"'ll\", 'be', 'a', 'pro', 'at', 'python', '!', 'python', 'is', 'a', 'great', 'and', 'friendly', 'language', 'to', 'use', 'and', 'learn', '.', 'it', 'fun', ',', 'and', 'can', 'be', 'adapted', 'to', 'both', 'small', 'and', 'large', 'projects', '.', 'python', 'will', 'cut', 'your', 'development', 'time', 'greatly', 'and', 'overall', ',', 'its', 'much', 'faster', 'to', 'write', 'python', 'than', 'other', 'languages', '.', 'this', 'course', 'will', 'be', 'a', 'quick', 'way', 'to', 'understand', 'all', 'the', 'major', 'concepts', 'of', 'python', 'programming', '.', 'you', \"'ll\", 'be', 'a', 'whiz', 'in', 'no', 'time', '.', 'this', 'course', 'is', 'a', 'one-stop-shop', 'for', 'everything', 'you', \"'ll\", 'need', 'to', 'know', 'to', 'get', 'started', 'with', 'python', ',', 'along', 'with', 'a', 'few', 'incentives', '.', 'we', \"'ll\", 'begin', 'with', 'the', 'basics', 'of', 'python', ',', 'learning', 'about', 'strings', ',', 'variables', ',', 'and', 'getting', 'to', 'know', 'the', 'data', 'types', '.', 'we', \"'ll\", 'soon', 'move', 'on', 'to', 'the', 'loops', 'and', 'conditions', 'in', 'python', '.', 'afterwards', ',', 'we', \"'ll\", 'discuss', 'a', 'bit', 'of', 'file', 'manipulation', 'and', 'functions', '.', 'by', 'then', ',', 'you', \"'ll\", 'know', 'all', 'the', 'basics', 'of', 'python', '.', 'i', 'hope', 'you', \"'re\", 'excited', 'to', 'dive', 'into', 'the', 'world', 'of', 'python', 'with', 'this', 'course', '.', 'well', ',', 'what', 'are', 'you', 'waiting', 'for', '?', 'let', \"'s\", 'get', 'started', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJLoOAmmW3WG"
      },
      "source": [
        "(d) Remove stopwords using stopwords from nltk or other sources and remove punctuation marks. (for all 3 documents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kaJbo9e3R8h"
      },
      "source": [
        "def rm_stopwords(filename):\n",
        "  return [word for word in filename if not word in stopwords and word.isalnum()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M52KxfpNW46B",
        "outputId": "d8258a7d-e49d-41f4-be8a-a9bc21c8d2e2"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "doc1_filtered_token, doc2_filtered_token, doc3_filtered_token = rm_stopwords(doc1_tokens), rm_stopwords(doc2_tokens), rm_stopwords(doc3_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nMJkKL54Jxu",
        "outputId": "149f6dfb-e3f5-4a3b-bbe0-a955bb2ff800"
      },
      "source": [
        "print(doc1_filtered_token)\n",
        "print(doc2_filtered_token)\n",
        "print(doc3_filtered_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['get', 'started', 'python', 'sections', 'linked', 'left', 'python', 'set', 'get', 'python', 'installed', 'machine', 'python', 'introduction', 'introduction', 'language', 'python', 'strings', 'starts', 'coding', 'material', 'leading', 'first', 'exercise', 'end', 'written', 'section', 'includes', 'link', 'code', 'exercise', 'section', 'material', 'lecture', 'videos', 'parallel', 'written', 'materials', 'introducing', 'python', 'strings', 'first', 'exercises', 'google', 'material', 'makes', 'intensive', 'class', 'videos', 'organized', 'sections', 'material', 'created', 'nick', 'parlante', 'working', 'engedu', 'group', 'google', 'special', 'thanks', 'help', 'google', 'colleagues', 'john', 'cox', 'steve', 'glassman', 'piotr', 'kaminksi', 'antoine', 'picard', 'finally', 'thanks', 'google', 'director', 'maggie', 'johnson', 'enlightened', 'generosity', 'put', 'materials', 'internet', 'free', 'creative', 'commons', 'attribution', 'license', 'share', 'enjoy']\n",
            "['welcome', 'google', 'python', 'online', 'tutorial', 'based', 'introductory', 'python', 'course', 'offered', 'internally', 'originally', 'created', 'python', 'days', 'tried', 'keep', 'content', 'universal', 'exercises', 'relevant', 'even', 'newer', 'releases', 'mentioned', 'setup', 'page', 'material', 'covers', 'python', 'recommend', 'avoiding', 'python', 'recognize', 'future', 'new', 'features', 'going', 'good', 'news', 'developers', 'learning', 'either', 'version', 'pick', 'without', 'much', 'difficulty', 'want', 'know', 'choosing', 'python', 'check', 'post']\n",
            "['need', 'quick', 'learning', 'python', 'first', 'time', 'come', 'right', 'place', 'let', 'get', 'started', 'learning', 'one', 'easiest', 'coding', 'languages', 'right', 'need', 'fret', 'coded', 'time', 'finish', 'course', 'pro', 'python', 'python', 'great', 'friendly', 'language', 'use', 'learn', 'fun', 'adapted', 'small', 'large', 'projects', 'python', 'cut', 'development', 'time', 'greatly', 'overall', 'much', 'faster', 'write', 'python', 'languages', 'course', 'quick', 'way', 'understand', 'major', 'concepts', 'python', 'programming', 'whiz', 'time', 'course', 'everything', 'need', 'know', 'get', 'started', 'python', 'along', 'incentives', 'begin', 'basics', 'python', 'learning', 'strings', 'variables', 'getting', 'know', 'data', 'types', 'soon', 'move', 'loops', 'conditions', 'python', 'afterwards', 'discuss', 'bit', 'file', 'manipulation', 'functions', 'know', 'basics', 'python', 'hope', 'excited', 'dive', 'world', 'python', 'course', 'well', 'waiting', 'let', 'get', 'started']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-gB0177W5co"
      },
      "source": [
        "(e) POS tagging for every term of 3 documents and display the result. (you can use print() to display or other ways to display). Comment on the result, whether all POS is correct or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_sP3WDzW7YY"
      },
      "source": [
        "def pos(filename, tag):\n",
        "  if tag == 'averaged':\n",
        "    return nltk.pos_tag(filename)\n",
        "  else:\n",
        "    return nltk.pos_tag(filename, tagset=tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_wX3Ic2Frlt",
        "outputId": "569700d9-d6d7-4695-daed-c90f9d43d097"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos1_avg, pos2_avg, pos3_avg = pos(doc1_filtered_token, 'averaged'), pos(doc2_filtered_token, 'averaged'), pos(doc3_filtered_token, 'averaged')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHAxRogFGsNo",
        "outputId": "61bf2b22-9821-496e-ad31-7f82ad9a5921"
      },
      "source": [
        "print(pos1_avg)\n",
        "print(pos2_avg)\n",
        "print(pos3_avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 'NN'), ('started', 'VBD'), ('python', 'JJ'), ('sections', 'NNS'), ('linked', 'VBN'), ('left', 'JJ'), ('python', 'NN'), ('set', 'VBN'), ('get', 'VB'), ('python', 'JJ'), ('installed', 'VBN'), ('machine', 'NN'), ('python', 'NN'), ('introduction', 'NN'), ('introduction', 'NN'), ('language', 'NN'), ('python', 'NN'), ('strings', 'NNS'), ('starts', 'VBZ'), ('coding', 'VBG'), ('material', 'NN'), ('leading', 'VBG'), ('first', 'JJ'), ('exercise', 'JJ'), ('end', 'NN'), ('written', 'VBN'), ('section', 'NN'), ('includes', 'VBZ'), ('link', 'VBP'), ('code', 'NN'), ('exercise', 'NN'), ('section', 'NN'), ('material', 'NN'), ('lecture', 'NN'), ('videos', 'FW'), ('parallel', 'JJ'), ('written', 'VBN'), ('materials', 'NNS'), ('introducing', 'VBG'), ('python', 'NN'), ('strings', 'NNS'), ('first', 'JJ'), ('exercises', 'VBZ'), ('google', 'JJ'), ('material', 'NN'), ('makes', 'VBZ'), ('intensive', 'JJ'), ('class', 'NN'), ('videos', 'NN'), ('organized', 'VBN'), ('sections', 'NNS'), ('material', 'NN'), ('created', 'VBD'), ('nick', 'JJ'), ('parlante', 'NN'), ('working', 'VBG'), ('engedu', 'JJ'), ('group', 'NN'), ('google', 'VBD'), ('special', 'JJ'), ('thanks', 'NNS'), ('help', 'VBP'), ('google', 'VB'), ('colleagues', 'NNS'), ('john', 'VB'), ('cox', 'NNS'), ('steve', 'VBP'), ('glassman', 'NN'), ('piotr', 'NN'), ('kaminksi', 'FW'), ('antoine', 'JJ'), ('picard', 'NN'), ('finally', 'RB'), ('thanks', 'NNS'), ('google', 'VBP'), ('director', 'NN'), ('maggie', 'NN'), ('johnson', 'NN'), ('enlightened', 'VBD'), ('generosity', 'NN'), ('put', 'VBN'), ('materials', 'NNS'), ('internet', 'VBP'), ('free', 'JJ'), ('creative', 'JJ'), ('commons', 'NNS'), ('attribution', 'NN'), ('license', 'NN'), ('share', 'NN'), ('enjoy', 'NN')]\n",
            "[('welcome', 'JJ'), ('google', 'NN'), ('python', 'NN'), ('online', 'VBP'), ('tutorial', 'NN'), ('based', 'VBN'), ('introductory', 'JJ'), ('python', 'JJ'), ('course', 'NN'), ('offered', 'VBN'), ('internally', 'RB'), ('originally', 'RB'), ('created', 'VBN'), ('python', 'NN'), ('days', 'NNS'), ('tried', 'VBD'), ('keep', 'JJ'), ('content', 'NN'), ('universal', 'NN'), ('exercises', 'VBZ'), ('relevant', 'JJ'), ('even', 'RB'), ('newer', 'JJR'), ('releases', 'NNS'), ('mentioned', 'VBD'), ('setup', 'JJ'), ('page', 'NN'), ('material', 'NN'), ('covers', 'VBZ'), ('python', 'JJ'), ('recommend', 'NN'), ('avoiding', 'VBG'), ('python', 'JJ'), ('recognize', 'VB'), ('future', 'JJ'), ('new', 'JJ'), ('features', 'NNS'), ('going', 'VBG'), ('good', 'JJ'), ('news', 'NN'), ('developers', 'NNS'), ('learning', 'VBG'), ('either', 'DT'), ('version', 'NN'), ('pick', 'NN'), ('without', 'IN'), ('much', 'JJ'), ('difficulty', 'NN'), ('want', 'VBP'), ('know', 'JJ'), ('choosing', 'VBG'), ('python', 'JJ'), ('check', 'NN'), ('post', 'NN')]\n",
            "[('need', 'NN'), ('quick', 'JJ'), ('learning', 'VBG'), ('python', 'NN'), ('first', 'JJ'), ('time', 'NN'), ('come', 'VB'), ('right', 'JJ'), ('place', 'NN'), ('let', 'VB'), ('get', 'VB'), ('started', 'VBN'), ('learning', 'VBG'), ('one', 'CD'), ('easiest', 'JJS'), ('coding', 'NN'), ('languages', 'NNS'), ('right', 'RB'), ('need', 'VBP'), ('fret', 'RB'), ('coded', 'JJ'), ('time', 'NN'), ('finish', 'JJ'), ('course', 'NN'), ('pro', 'JJ'), ('python', 'NN'), ('python', 'NN'), ('great', 'JJ'), ('friendly', 'JJ'), ('language', 'NN'), ('use', 'NN'), ('learn', 'FW'), ('fun', 'NN'), ('adapted', 'VBD'), ('small', 'JJ'), ('large', 'JJ'), ('projects', 'NNS'), ('python', 'VBP'), ('cut', 'VB'), ('development', 'NN'), ('time', 'NN'), ('greatly', 'RB'), ('overall', 'JJ'), ('much', 'JJ'), ('faster', 'JJR'), ('write', 'JJ'), ('python', 'NN'), ('languages', 'NNS'), ('course', 'NN'), ('quick', 'JJ'), ('way', 'NN'), ('understand', 'IN'), ('major', 'JJ'), ('concepts', 'NNS'), ('python', 'VBP'), ('programming', 'VBG'), ('whiz', 'JJ'), ('time', 'NN'), ('course', 'NN'), ('everything', 'NN'), ('need', 'NN'), ('know', 'VBP'), ('get', 'VB'), ('started', 'VBN'), ('python', 'RB'), ('along', 'IN'), ('incentives', 'NNS'), ('begin', 'VBP'), ('basics', 'NNS'), ('python', 'VBP'), ('learning', 'VBG'), ('strings', 'NNS'), ('variables', 'NNS'), ('getting', 'VBG'), ('know', 'VBP'), ('data', 'NNS'), ('types', 'NNS'), ('soon', 'RB'), ('move', 'VBP'), ('loops', 'JJ'), ('conditions', 'NNS'), ('python', 'VBP'), ('afterwards', 'NNS'), ('discuss', 'JJ'), ('bit', 'NN'), ('file', 'JJ'), ('manipulation', 'NN'), ('functions', 'NNS'), ('know', 'VBP'), ('basics', 'NNS'), ('python', 'VBP'), ('hope', 'NN'), ('excited', 'VBN'), ('dive', 'JJ'), ('world', 'NN'), ('python', 'NN'), ('course', 'NN'), ('well', 'RB'), ('waiting', 'VBG'), ('let', 'VB'), ('get', 'VB'), ('started', 'VBN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC9MbORzCHBN",
        "outputId": "1f26088d-38b6-4e26-934f-33214b85db01"
      },
      "source": [
        "nltk.download('universal_tagset')\n",
        "pos1, pos2, pos3 = pos(doc1_filtered_token, 'universal'), pos(doc2_filtered_token, 'universal'), pos(doc3_filtered_token, 'universal')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izhd7fEMCZRa",
        "outputId": "f88fe338-1c5b-4b70-e9a0-dff0ecc4f2a5"
      },
      "source": [
        "print(pos1)\n",
        "print(pos2)\n",
        "print(pos3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 'NOUN'), ('started', 'VERB'), ('python', 'ADJ'), ('sections', 'NOUN'), ('linked', 'VERB'), ('left', 'ADJ'), ('python', 'NOUN'), ('set', 'VERB'), ('get', 'VERB'), ('python', 'ADJ'), ('installed', 'VERB'), ('machine', 'NOUN'), ('python', 'NOUN'), ('introduction', 'NOUN'), ('introduction', 'NOUN'), ('language', 'NOUN'), ('python', 'NOUN'), ('strings', 'NOUN'), ('starts', 'VERB'), ('coding', 'VERB'), ('material', 'NOUN'), ('leading', 'VERB'), ('first', 'ADJ'), ('exercise', 'ADJ'), ('end', 'NOUN'), ('written', 'VERB'), ('section', 'NOUN'), ('includes', 'VERB'), ('link', 'VERB'), ('code', 'NOUN'), ('exercise', 'NOUN'), ('section', 'NOUN'), ('material', 'NOUN'), ('lecture', 'NOUN'), ('videos', 'X'), ('parallel', 'ADJ'), ('written', 'VERB'), ('materials', 'NOUN'), ('introducing', 'VERB'), ('python', 'NOUN'), ('strings', 'NOUN'), ('first', 'ADJ'), ('exercises', 'VERB'), ('google', 'ADJ'), ('material', 'NOUN'), ('makes', 'VERB'), ('intensive', 'ADJ'), ('class', 'NOUN'), ('videos', 'NOUN'), ('organized', 'VERB'), ('sections', 'NOUN'), ('material', 'NOUN'), ('created', 'VERB'), ('nick', 'ADJ'), ('parlante', 'NOUN'), ('working', 'VERB'), ('engedu', 'ADJ'), ('group', 'NOUN'), ('google', 'VERB'), ('special', 'ADJ'), ('thanks', 'NOUN'), ('help', 'VERB'), ('google', 'VERB'), ('colleagues', 'NOUN'), ('john', 'VERB'), ('cox', 'NOUN'), ('steve', 'VERB'), ('glassman', 'NOUN'), ('piotr', 'NOUN'), ('kaminksi', 'X'), ('antoine', 'ADJ'), ('picard', 'NOUN'), ('finally', 'ADV'), ('thanks', 'NOUN'), ('google', 'VERB'), ('director', 'NOUN'), ('maggie', 'NOUN'), ('johnson', 'NOUN'), ('enlightened', 'VERB'), ('generosity', 'NOUN'), ('put', 'VERB'), ('materials', 'NOUN'), ('internet', 'VERB'), ('free', 'ADJ'), ('creative', 'ADJ'), ('commons', 'NOUN'), ('attribution', 'NOUN'), ('license', 'NOUN'), ('share', 'NOUN'), ('enjoy', 'NOUN')]\n",
            "[('welcome', 'ADJ'), ('google', 'NOUN'), ('python', 'NOUN'), ('online', 'VERB'), ('tutorial', 'NOUN'), ('based', 'VERB'), ('introductory', 'ADJ'), ('python', 'ADJ'), ('course', 'NOUN'), ('offered', 'VERB'), ('internally', 'ADV'), ('originally', 'ADV'), ('created', 'VERB'), ('python', 'NOUN'), ('days', 'NOUN'), ('tried', 'VERB'), ('keep', 'ADJ'), ('content', 'NOUN'), ('universal', 'NOUN'), ('exercises', 'VERB'), ('relevant', 'ADJ'), ('even', 'ADV'), ('newer', 'ADJ'), ('releases', 'NOUN'), ('mentioned', 'VERB'), ('setup', 'ADJ'), ('page', 'NOUN'), ('material', 'NOUN'), ('covers', 'VERB'), ('python', 'ADJ'), ('recommend', 'NOUN'), ('avoiding', 'VERB'), ('python', 'ADJ'), ('recognize', 'VERB'), ('future', 'ADJ'), ('new', 'ADJ'), ('features', 'NOUN'), ('going', 'VERB'), ('good', 'ADJ'), ('news', 'NOUN'), ('developers', 'NOUN'), ('learning', 'VERB'), ('either', 'DET'), ('version', 'NOUN'), ('pick', 'NOUN'), ('without', 'ADP'), ('much', 'ADJ'), ('difficulty', 'NOUN'), ('want', 'VERB'), ('know', 'ADJ'), ('choosing', 'VERB'), ('python', 'ADJ'), ('check', 'NOUN'), ('post', 'NOUN')]\n",
            "[('need', 'NOUN'), ('quick', 'ADJ'), ('learning', 'VERB'), ('python', 'NOUN'), ('first', 'ADJ'), ('time', 'NOUN'), ('come', 'VERB'), ('right', 'ADJ'), ('place', 'NOUN'), ('let', 'VERB'), ('get', 'VERB'), ('started', 'VERB'), ('learning', 'VERB'), ('one', 'NUM'), ('easiest', 'ADJ'), ('coding', 'NOUN'), ('languages', 'NOUN'), ('right', 'ADV'), ('need', 'VERB'), ('fret', 'ADV'), ('coded', 'ADJ'), ('time', 'NOUN'), ('finish', 'ADJ'), ('course', 'NOUN'), ('pro', 'ADJ'), ('python', 'NOUN'), ('python', 'NOUN'), ('great', 'ADJ'), ('friendly', 'ADJ'), ('language', 'NOUN'), ('use', 'NOUN'), ('learn', 'X'), ('fun', 'NOUN'), ('adapted', 'VERB'), ('small', 'ADJ'), ('large', 'ADJ'), ('projects', 'NOUN'), ('python', 'VERB'), ('cut', 'VERB'), ('development', 'NOUN'), ('time', 'NOUN'), ('greatly', 'ADV'), ('overall', 'ADJ'), ('much', 'ADJ'), ('faster', 'ADJ'), ('write', 'ADJ'), ('python', 'NOUN'), ('languages', 'NOUN'), ('course', 'NOUN'), ('quick', 'ADJ'), ('way', 'NOUN'), ('understand', 'ADP'), ('major', 'ADJ'), ('concepts', 'NOUN'), ('python', 'VERB'), ('programming', 'VERB'), ('whiz', 'ADJ'), ('time', 'NOUN'), ('course', 'NOUN'), ('everything', 'NOUN'), ('need', 'NOUN'), ('know', 'VERB'), ('get', 'VERB'), ('started', 'VERB'), ('python', 'ADV'), ('along', 'ADP'), ('incentives', 'NOUN'), ('begin', 'VERB'), ('basics', 'NOUN'), ('python', 'VERB'), ('learning', 'VERB'), ('strings', 'NOUN'), ('variables', 'NOUN'), ('getting', 'VERB'), ('know', 'VERB'), ('data', 'NOUN'), ('types', 'NOUN'), ('soon', 'ADV'), ('move', 'VERB'), ('loops', 'ADJ'), ('conditions', 'NOUN'), ('python', 'VERB'), ('afterwards', 'NOUN'), ('discuss', 'ADJ'), ('bit', 'NOUN'), ('file', 'ADJ'), ('manipulation', 'NOUN'), ('functions', 'NOUN'), ('know', 'VERB'), ('basics', 'NOUN'), ('python', 'VERB'), ('hope', 'NOUN'), ('excited', 'VERB'), ('dive', 'ADJ'), ('world', 'NOUN'), ('python', 'NOUN'), ('course', 'NOUN'), ('well', 'ADV'), ('waiting', 'VERB'), ('let', 'VERB'), ('get', 'VERB'), ('started', 'VERB')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqcRzvuuW-Ty"
      },
      "source": [
        "2. Feature selection and tfidf weighting (45%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1r38RUjXPUE"
      },
      "source": [
        "(a) After removing all terms that are not Verb, Noun, Adjective, compute tfidf weighting for every term in the three documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCZPcEjlXAdq"
      },
      "source": [
        "import spacy\n",
        "def feature_selection(filename):\n",
        "  nlp = spacy.load('en_core_web_sm') #you can use other methods\n",
        "  # excluded tags\n",
        "  excluded_tags = {\"NOUN\", \"VERB\", \"ADJ\"}\n",
        "  new_sentences = []\n",
        "\n",
        "  for i, j in filename:\n",
        "      if j in excluded_tags:\n",
        "          new_sentences.append(i)\n",
        "  return new_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWFhF1SeGQyU",
        "outputId": "f9e5fc6f-0ad9-4bf0-b0ee-d18740eaa63e"
      },
      "source": [
        "doc_all = {\"doc1\":feature_selection(pos1), \"doc2\":feature_selection(pos2), \"doc3\":feature_selection(pos3)}\n",
        "print(doc_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc1': ['get', 'started', 'python', 'sections', 'linked', 'left', 'python', 'set', 'get', 'python', 'installed', 'machine', 'python', 'introduction', 'introduction', 'language', 'python', 'strings', 'starts', 'coding', 'material', 'leading', 'first', 'exercise', 'end', 'written', 'section', 'includes', 'link', 'code', 'exercise', 'section', 'material', 'lecture', 'parallel', 'written', 'materials', 'introducing', 'python', 'strings', 'first', 'exercises', 'google', 'material', 'makes', 'intensive', 'class', 'videos', 'organized', 'sections', 'material', 'created', 'nick', 'parlante', 'working', 'engedu', 'group', 'google', 'special', 'thanks', 'help', 'google', 'colleagues', 'john', 'cox', 'steve', 'glassman', 'piotr', 'antoine', 'picard', 'thanks', 'google', 'director', 'maggie', 'johnson', 'enlightened', 'generosity', 'put', 'materials', 'internet', 'free', 'creative', 'commons', 'attribution', 'license', 'share', 'enjoy'], 'doc2': ['welcome', 'google', 'python', 'online', 'tutorial', 'based', 'introductory', 'python', 'course', 'offered', 'created', 'python', 'days', 'tried', 'keep', 'content', 'universal', 'exercises', 'relevant', 'newer', 'releases', 'mentioned', 'setup', 'page', 'material', 'covers', 'python', 'recommend', 'avoiding', 'python', 'recognize', 'future', 'new', 'features', 'going', 'good', 'news', 'developers', 'learning', 'version', 'pick', 'much', 'difficulty', 'want', 'know', 'choosing', 'python', 'check', 'post'], 'doc3': ['need', 'quick', 'learning', 'python', 'first', 'time', 'come', 'right', 'place', 'let', 'get', 'started', 'learning', 'easiest', 'coding', 'languages', 'need', 'coded', 'time', 'finish', 'course', 'pro', 'python', 'python', 'great', 'friendly', 'language', 'use', 'fun', 'adapted', 'small', 'large', 'projects', 'python', 'cut', 'development', 'time', 'overall', 'much', 'faster', 'write', 'python', 'languages', 'course', 'quick', 'way', 'major', 'concepts', 'python', 'programming', 'whiz', 'time', 'course', 'everything', 'need', 'know', 'get', 'started', 'incentives', 'begin', 'basics', 'python', 'learning', 'strings', 'variables', 'getting', 'know', 'data', 'types', 'move', 'loops', 'conditions', 'python', 'afterwards', 'discuss', 'bit', 'file', 'manipulation', 'functions', 'know', 'basics', 'python', 'hope', 'excited', 'dive', 'world', 'python', 'course', 'waiting', 'let', 'get', 'started']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsIhF5o2GhHS"
      },
      "source": [
        "# create tf function\n",
        "def tf(term, token_doc):\n",
        "    tf = token_doc.count(term)/len(token_doc)\n",
        "    return tf\n",
        "\n",
        "# create function to calculate how many doc contain the term \n",
        "def numDocsContaining(word, token_doclist):\n",
        "    doccount = 0\n",
        "    for doc_token in token_doclist:\n",
        "        if doc_token.count(word) > 0:\n",
        "            doccount +=1\n",
        "    return doccount\n",
        "  \n",
        "import math\n",
        "# create function to calculate  Inverse Document Frequency in doclist\n",
        "def idf(word, token_doclist):\n",
        "    n = len(token_doclist)\n",
        "    df = numDocsContaining(word, token_doclist)\n",
        "    return math.log10(n/df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbLl_cnEGqp7",
        "outputId": "78792c7a-d643-40f0-ca1e-dac26896105b"
      },
      "source": [
        "bag_words =[] # declare bag_words is a list\n",
        "for doc in doc_all.keys():\n",
        "  bag_words += doc_all[doc]\n",
        "bag_words=set(bag_words)\n",
        "print(bag_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'installed', 'avoiding', 'makes', 'director', 'starts', 'relevant', 'want', 'manipulation', 'language', 'get', 'content', 'friendly', 'leading', 'quick', 'post', 'section', 'parallel', 'hope', 'working', 'mentioned', 'help', 'videos', 'major', 'overall', 'begin', 'code', 'thanks', 'strings', 'let', 'adapted', 'faster', 'getting', 'license', 'universal', 'creative', 'going', 'functions', 'great', 'keep', 'organized', 'attribution', 'future', 'parlante', 'exercise', 'written', 'johnson', 'material', 'group', 'programming', 'new', 'first', 'introducing', 'piotr', 'move', 'cut', 'commons', 'engedu', 'internet', 'free', 'python', 'releases', 'recognize', 'class', 'maggie', 'dive', 'picard', 'includes', 'online', 'time', 'linked', 'fun', 'check', 'basics', 'excited', 'need', 'place', 'newer', 'end', 'pro', 'sections', 'antoine', 'whiz', 'set', 'come', 'afterwards', 'exercises', 'concepts', 'way', 'welcome', 'projects', 'world', 'intensive', 'conditions', 'finish', 'lecture', 'loops', 'coding', 'left', 'steve', 'version', 'put', 'good', 'bit', 'days', 'learning', 'covers', 'started', 'based', 'google', 'development', 'tutorial', 'share', 'machine', 'choosing', 'types', 'everything', 'link', 'features', 'variables', 'data', 'nick', 'enlightened', 'course', 'coded', 'news', 'difficulty', 'tried', 'use', 'small', 'created', 'enjoy', 'john', 'pick', 'page', 'easiest', 'glassman', 'cox', 'incentives', 'offered', 'generosity', 'materials', 'much', 'colleagues', 'waiting', 'large', 'recommend', 'languages', 'setup', 'discuss', 'introductory', 'right', 'know', 'file', 'developers', 'introduction', 'write', 'special'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8nUWjsIGrdm",
        "outputId": "7cd75e50-7510-4e55-9368-35a3151b6108"
      },
      "source": [
        "#calculate idf for every word in bag_words\n",
        "bag_words_idf={} # declare \"bag_words_idf\" data structure is dictionary \n",
        "for word in bag_words:\n",
        "  bag_words_idf[word]= idf(word,doc_all.values())\n",
        "print(bag_words_idf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'installed': 0.47712125471966244, 'avoiding': 0.47712125471966244, 'makes': 0.47712125471966244, 'director': 0.47712125471966244, 'starts': 0.47712125471966244, 'relevant': 0.47712125471966244, 'want': 0.47712125471966244, 'manipulation': 0.47712125471966244, 'language': 0.17609125905568124, 'get': 0.17609125905568124, 'content': 0.47712125471966244, 'friendly': 0.47712125471966244, 'leading': 0.47712125471966244, 'quick': 0.47712125471966244, 'post': 0.47712125471966244, 'section': 0.47712125471966244, 'parallel': 0.47712125471966244, 'hope': 0.47712125471966244, 'working': 0.47712125471966244, 'mentioned': 0.47712125471966244, 'help': 0.47712125471966244, 'videos': 0.47712125471966244, 'major': 0.47712125471966244, 'overall': 0.47712125471966244, 'begin': 0.47712125471966244, 'code': 0.47712125471966244, 'thanks': 0.47712125471966244, 'strings': 0.17609125905568124, 'let': 0.47712125471966244, 'adapted': 0.47712125471966244, 'faster': 0.47712125471966244, 'getting': 0.47712125471966244, 'license': 0.47712125471966244, 'universal': 0.47712125471966244, 'creative': 0.47712125471966244, 'going': 0.47712125471966244, 'functions': 0.47712125471966244, 'great': 0.47712125471966244, 'keep': 0.47712125471966244, 'organized': 0.47712125471966244, 'attribution': 0.47712125471966244, 'future': 0.47712125471966244, 'parlante': 0.47712125471966244, 'exercise': 0.47712125471966244, 'written': 0.47712125471966244, 'johnson': 0.47712125471966244, 'material': 0.17609125905568124, 'group': 0.47712125471966244, 'programming': 0.47712125471966244, 'new': 0.47712125471966244, 'first': 0.17609125905568124, 'introducing': 0.47712125471966244, 'piotr': 0.47712125471966244, 'move': 0.47712125471966244, 'cut': 0.47712125471966244, 'commons': 0.47712125471966244, 'engedu': 0.47712125471966244, 'internet': 0.47712125471966244, 'free': 0.47712125471966244, 'python': 0.0, 'releases': 0.47712125471966244, 'recognize': 0.47712125471966244, 'class': 0.47712125471966244, 'maggie': 0.47712125471966244, 'dive': 0.47712125471966244, 'picard': 0.47712125471966244, 'includes': 0.47712125471966244, 'online': 0.47712125471966244, 'time': 0.47712125471966244, 'linked': 0.47712125471966244, 'fun': 0.47712125471966244, 'check': 0.47712125471966244, 'basics': 0.47712125471966244, 'excited': 0.47712125471966244, 'need': 0.47712125471966244, 'place': 0.47712125471966244, 'newer': 0.47712125471966244, 'end': 0.47712125471966244, 'pro': 0.47712125471966244, 'sections': 0.47712125471966244, 'antoine': 0.47712125471966244, 'whiz': 0.47712125471966244, 'set': 0.47712125471966244, 'come': 0.47712125471966244, 'afterwards': 0.47712125471966244, 'exercises': 0.17609125905568124, 'concepts': 0.47712125471966244, 'way': 0.47712125471966244, 'welcome': 0.47712125471966244, 'projects': 0.47712125471966244, 'world': 0.47712125471966244, 'intensive': 0.47712125471966244, 'conditions': 0.47712125471966244, 'finish': 0.47712125471966244, 'lecture': 0.47712125471966244, 'loops': 0.47712125471966244, 'coding': 0.17609125905568124, 'left': 0.47712125471966244, 'steve': 0.47712125471966244, 'version': 0.47712125471966244, 'put': 0.47712125471966244, 'good': 0.47712125471966244, 'bit': 0.47712125471966244, 'days': 0.47712125471966244, 'learning': 0.17609125905568124, 'covers': 0.47712125471966244, 'started': 0.17609125905568124, 'based': 0.47712125471966244, 'google': 0.17609125905568124, 'development': 0.47712125471966244, 'tutorial': 0.47712125471966244, 'share': 0.47712125471966244, 'machine': 0.47712125471966244, 'choosing': 0.47712125471966244, 'types': 0.47712125471966244, 'everything': 0.47712125471966244, 'link': 0.47712125471966244, 'features': 0.47712125471966244, 'variables': 0.47712125471966244, 'data': 0.47712125471966244, 'nick': 0.47712125471966244, 'enlightened': 0.47712125471966244, 'course': 0.17609125905568124, 'coded': 0.47712125471966244, 'news': 0.47712125471966244, 'difficulty': 0.47712125471966244, 'tried': 0.47712125471966244, 'use': 0.47712125471966244, 'small': 0.47712125471966244, 'created': 0.17609125905568124, 'enjoy': 0.47712125471966244, 'john': 0.47712125471966244, 'pick': 0.47712125471966244, 'page': 0.47712125471966244, 'easiest': 0.47712125471966244, 'glassman': 0.47712125471966244, 'cox': 0.47712125471966244, 'incentives': 0.47712125471966244, 'offered': 0.47712125471966244, 'generosity': 0.47712125471966244, 'materials': 0.47712125471966244, 'much': 0.17609125905568124, 'colleagues': 0.47712125471966244, 'waiting': 0.47712125471966244, 'large': 0.47712125471966244, 'recommend': 0.47712125471966244, 'languages': 0.47712125471966244, 'setup': 0.47712125471966244, 'discuss': 0.47712125471966244, 'introductory': 0.47712125471966244, 'right': 0.47712125471966244, 'know': 0.17609125905568124, 'file': 0.47712125471966244, 'developers': 0.47712125471966244, 'introduction': 0.47712125471966244, 'write': 0.47712125471966244, 'special': 0.47712125471966244}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "226_rr94GtHS",
        "outputId": "06c1cc11-2002-4d62-f171-1e6143f9c4a1"
      },
      "source": [
        "#calculate tfidf\n",
        "tfidf={} # declare tfidf dictionary to store tfidf value\n",
        "for doc in doc_all.keys():\n",
        "  tfidf_doc={} # delare tfidf_doc as a dictionary to store tfidf of each doc\n",
        "  for term in bag_words:\n",
        "    tfidf_doc[term]= tf(term,doc_all[doc]) * bag_words_idf[term] # calculate tfidf for each doc\n",
        "  tfidf[doc]= tfidf_doc\n",
        "\n",
        "tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc1': {'adapted': 0.0,\n",
              "  'afterwards': 0.0,\n",
              "  'antoine': 0.005484152353099568,\n",
              "  'attribution': 0.005484152353099568,\n",
              "  'avoiding': 0.0,\n",
              "  'based': 0.0,\n",
              "  'basics': 0.0,\n",
              "  'begin': 0.0,\n",
              "  'bit': 0.0,\n",
              "  'check': 0.0,\n",
              "  'choosing': 0.0,\n",
              "  'class': 0.005484152353099568,\n",
              "  'code': 0.005484152353099568,\n",
              "  'coded': 0.0,\n",
              "  'coding': 0.002024037460410129,\n",
              "  'colleagues': 0.005484152353099568,\n",
              "  'come': 0.0,\n",
              "  'commons': 0.005484152353099568,\n",
              "  'concepts': 0.0,\n",
              "  'conditions': 0.0,\n",
              "  'content': 0.0,\n",
              "  'course': 0.0,\n",
              "  'covers': 0.0,\n",
              "  'cox': 0.005484152353099568,\n",
              "  'created': 0.002024037460410129,\n",
              "  'creative': 0.005484152353099568,\n",
              "  'cut': 0.0,\n",
              "  'data': 0.0,\n",
              "  'days': 0.0,\n",
              "  'developers': 0.0,\n",
              "  'development': 0.0,\n",
              "  'difficulty': 0.0,\n",
              "  'director': 0.005484152353099568,\n",
              "  'discuss': 0.0,\n",
              "  'dive': 0.0,\n",
              "  'easiest': 0.0,\n",
              "  'end': 0.005484152353099568,\n",
              "  'engedu': 0.005484152353099568,\n",
              "  'enjoy': 0.005484152353099568,\n",
              "  'enlightened': 0.005484152353099568,\n",
              "  'everything': 0.0,\n",
              "  'excited': 0.0,\n",
              "  'exercise': 0.010968304706199136,\n",
              "  'exercises': 0.002024037460410129,\n",
              "  'faster': 0.0,\n",
              "  'features': 0.0,\n",
              "  'file': 0.0,\n",
              "  'finish': 0.0,\n",
              "  'first': 0.004048074920820258,\n",
              "  'free': 0.005484152353099568,\n",
              "  'friendly': 0.0,\n",
              "  'fun': 0.0,\n",
              "  'functions': 0.0,\n",
              "  'future': 0.0,\n",
              "  'generosity': 0.005484152353099568,\n",
              "  'get': 0.004048074920820258,\n",
              "  'getting': 0.0,\n",
              "  'glassman': 0.005484152353099568,\n",
              "  'going': 0.0,\n",
              "  'good': 0.0,\n",
              "  'google': 0.008096149841640516,\n",
              "  'great': 0.0,\n",
              "  'group': 0.005484152353099568,\n",
              "  'help': 0.005484152353099568,\n",
              "  'hope': 0.0,\n",
              "  'incentives': 0.0,\n",
              "  'includes': 0.005484152353099568,\n",
              "  'installed': 0.005484152353099568,\n",
              "  'intensive': 0.005484152353099568,\n",
              "  'internet': 0.005484152353099568,\n",
              "  'introducing': 0.005484152353099568,\n",
              "  'introduction': 0.010968304706199136,\n",
              "  'introductory': 0.0,\n",
              "  'john': 0.005484152353099568,\n",
              "  'johnson': 0.005484152353099568,\n",
              "  'keep': 0.0,\n",
              "  'know': 0.0,\n",
              "  'language': 0.002024037460410129,\n",
              "  'languages': 0.0,\n",
              "  'large': 0.0,\n",
              "  'leading': 0.005484152353099568,\n",
              "  'learning': 0.0,\n",
              "  'lecture': 0.005484152353099568,\n",
              "  'left': 0.005484152353099568,\n",
              "  'let': 0.0,\n",
              "  'license': 0.005484152353099568,\n",
              "  'link': 0.005484152353099568,\n",
              "  'linked': 0.005484152353099568,\n",
              "  'loops': 0.0,\n",
              "  'machine': 0.005484152353099568,\n",
              "  'maggie': 0.005484152353099568,\n",
              "  'major': 0.0,\n",
              "  'makes': 0.005484152353099568,\n",
              "  'manipulation': 0.0,\n",
              "  'material': 0.008096149841640516,\n",
              "  'materials': 0.010968304706199136,\n",
              "  'mentioned': 0.0,\n",
              "  'move': 0.0,\n",
              "  'much': 0.0,\n",
              "  'need': 0.0,\n",
              "  'new': 0.0,\n",
              "  'newer': 0.0,\n",
              "  'news': 0.0,\n",
              "  'nick': 0.005484152353099568,\n",
              "  'offered': 0.0,\n",
              "  'online': 0.0,\n",
              "  'organized': 0.005484152353099568,\n",
              "  'overall': 0.0,\n",
              "  'page': 0.0,\n",
              "  'parallel': 0.005484152353099568,\n",
              "  'parlante': 0.005484152353099568,\n",
              "  'picard': 0.005484152353099568,\n",
              "  'pick': 0.0,\n",
              "  'piotr': 0.005484152353099568,\n",
              "  'place': 0.0,\n",
              "  'post': 0.0,\n",
              "  'pro': 0.0,\n",
              "  'programming': 0.0,\n",
              "  'projects': 0.0,\n",
              "  'put': 0.005484152353099568,\n",
              "  'python': 0.0,\n",
              "  'quick': 0.0,\n",
              "  'recognize': 0.0,\n",
              "  'recommend': 0.0,\n",
              "  'releases': 0.0,\n",
              "  'relevant': 0.0,\n",
              "  'right': 0.0,\n",
              "  'section': 0.010968304706199136,\n",
              "  'sections': 0.010968304706199136,\n",
              "  'set': 0.005484152353099568,\n",
              "  'setup': 0.0,\n",
              "  'share': 0.005484152353099568,\n",
              "  'small': 0.0,\n",
              "  'special': 0.005484152353099568,\n",
              "  'started': 0.002024037460410129,\n",
              "  'starts': 0.005484152353099568,\n",
              "  'steve': 0.005484152353099568,\n",
              "  'strings': 0.004048074920820258,\n",
              "  'thanks': 0.010968304706199136,\n",
              "  'time': 0.0,\n",
              "  'tried': 0.0,\n",
              "  'tutorial': 0.0,\n",
              "  'types': 0.0,\n",
              "  'universal': 0.0,\n",
              "  'use': 0.0,\n",
              "  'variables': 0.0,\n",
              "  'version': 0.0,\n",
              "  'videos': 0.005484152353099568,\n",
              "  'waiting': 0.0,\n",
              "  'want': 0.0,\n",
              "  'way': 0.0,\n",
              "  'welcome': 0.0,\n",
              "  'whiz': 0.0,\n",
              "  'working': 0.005484152353099568,\n",
              "  'world': 0.0,\n",
              "  'write': 0.0,\n",
              "  'written': 0.010968304706199136},\n",
              " 'doc2': {'adapted': 0.0,\n",
              "  'afterwards': 0.0,\n",
              "  'antoine': 0.0,\n",
              "  'attribution': 0.0,\n",
              "  'avoiding': 0.00973716846366658,\n",
              "  'based': 0.00973716846366658,\n",
              "  'basics': 0.0,\n",
              "  'begin': 0.0,\n",
              "  'bit': 0.0,\n",
              "  'check': 0.00973716846366658,\n",
              "  'choosing': 0.00973716846366658,\n",
              "  'class': 0.0,\n",
              "  'code': 0.0,\n",
              "  'coded': 0.0,\n",
              "  'coding': 0.0,\n",
              "  'colleagues': 0.0,\n",
              "  'come': 0.0,\n",
              "  'commons': 0.0,\n",
              "  'concepts': 0.0,\n",
              "  'conditions': 0.0,\n",
              "  'content': 0.00973716846366658,\n",
              "  'course': 0.0035936991644016578,\n",
              "  'covers': 0.00973716846366658,\n",
              "  'cox': 0.0,\n",
              "  'created': 0.0035936991644016578,\n",
              "  'creative': 0.0,\n",
              "  'cut': 0.0,\n",
              "  'data': 0.0,\n",
              "  'days': 0.00973716846366658,\n",
              "  'developers': 0.00973716846366658,\n",
              "  'development': 0.0,\n",
              "  'difficulty': 0.00973716846366658,\n",
              "  'director': 0.0,\n",
              "  'discuss': 0.0,\n",
              "  'dive': 0.0,\n",
              "  'easiest': 0.0,\n",
              "  'end': 0.0,\n",
              "  'engedu': 0.0,\n",
              "  'enjoy': 0.0,\n",
              "  'enlightened': 0.0,\n",
              "  'everything': 0.0,\n",
              "  'excited': 0.0,\n",
              "  'exercise': 0.0,\n",
              "  'exercises': 0.0035936991644016578,\n",
              "  'faster': 0.0,\n",
              "  'features': 0.00973716846366658,\n",
              "  'file': 0.0,\n",
              "  'finish': 0.0,\n",
              "  'first': 0.0,\n",
              "  'free': 0.0,\n",
              "  'friendly': 0.0,\n",
              "  'fun': 0.0,\n",
              "  'functions': 0.0,\n",
              "  'future': 0.00973716846366658,\n",
              "  'generosity': 0.0,\n",
              "  'get': 0.0,\n",
              "  'getting': 0.0,\n",
              "  'glassman': 0.0,\n",
              "  'going': 0.00973716846366658,\n",
              "  'good': 0.00973716846366658,\n",
              "  'google': 0.0035936991644016578,\n",
              "  'great': 0.0,\n",
              "  'group': 0.0,\n",
              "  'help': 0.0,\n",
              "  'hope': 0.0,\n",
              "  'incentives': 0.0,\n",
              "  'includes': 0.0,\n",
              "  'installed': 0.0,\n",
              "  'intensive': 0.0,\n",
              "  'internet': 0.0,\n",
              "  'introducing': 0.0,\n",
              "  'introduction': 0.0,\n",
              "  'introductory': 0.00973716846366658,\n",
              "  'john': 0.0,\n",
              "  'johnson': 0.0,\n",
              "  'keep': 0.00973716846366658,\n",
              "  'know': 0.0035936991644016578,\n",
              "  'language': 0.0,\n",
              "  'languages': 0.0,\n",
              "  'large': 0.0,\n",
              "  'leading': 0.0,\n",
              "  'learning': 0.0035936991644016578,\n",
              "  'lecture': 0.0,\n",
              "  'left': 0.0,\n",
              "  'let': 0.0,\n",
              "  'license': 0.0,\n",
              "  'link': 0.0,\n",
              "  'linked': 0.0,\n",
              "  'loops': 0.0,\n",
              "  'machine': 0.0,\n",
              "  'maggie': 0.0,\n",
              "  'major': 0.0,\n",
              "  'makes': 0.0,\n",
              "  'manipulation': 0.0,\n",
              "  'material': 0.0035936991644016578,\n",
              "  'materials': 0.0,\n",
              "  'mentioned': 0.00973716846366658,\n",
              "  'move': 0.0,\n",
              "  'much': 0.0035936991644016578,\n",
              "  'need': 0.0,\n",
              "  'new': 0.00973716846366658,\n",
              "  'newer': 0.00973716846366658,\n",
              "  'news': 0.00973716846366658,\n",
              "  'nick': 0.0,\n",
              "  'offered': 0.00973716846366658,\n",
              "  'online': 0.00973716846366658,\n",
              "  'organized': 0.0,\n",
              "  'overall': 0.0,\n",
              "  'page': 0.00973716846366658,\n",
              "  'parallel': 0.0,\n",
              "  'parlante': 0.0,\n",
              "  'picard': 0.0,\n",
              "  'pick': 0.00973716846366658,\n",
              "  'piotr': 0.0,\n",
              "  'place': 0.0,\n",
              "  'post': 0.00973716846366658,\n",
              "  'pro': 0.0,\n",
              "  'programming': 0.0,\n",
              "  'projects': 0.0,\n",
              "  'put': 0.0,\n",
              "  'python': 0.0,\n",
              "  'quick': 0.0,\n",
              "  'recognize': 0.00973716846366658,\n",
              "  'recommend': 0.00973716846366658,\n",
              "  'releases': 0.00973716846366658,\n",
              "  'relevant': 0.00973716846366658,\n",
              "  'right': 0.0,\n",
              "  'section': 0.0,\n",
              "  'sections': 0.0,\n",
              "  'set': 0.0,\n",
              "  'setup': 0.00973716846366658,\n",
              "  'share': 0.0,\n",
              "  'small': 0.0,\n",
              "  'special': 0.0,\n",
              "  'started': 0.0,\n",
              "  'starts': 0.0,\n",
              "  'steve': 0.0,\n",
              "  'strings': 0.0,\n",
              "  'thanks': 0.0,\n",
              "  'time': 0.0,\n",
              "  'tried': 0.00973716846366658,\n",
              "  'tutorial': 0.00973716846366658,\n",
              "  'types': 0.0,\n",
              "  'universal': 0.00973716846366658,\n",
              "  'use': 0.0,\n",
              "  'variables': 0.0,\n",
              "  'version': 0.00973716846366658,\n",
              "  'videos': 0.0,\n",
              "  'waiting': 0.0,\n",
              "  'want': 0.00973716846366658,\n",
              "  'way': 0.0,\n",
              "  'welcome': 0.00973716846366658,\n",
              "  'whiz': 0.0,\n",
              "  'working': 0.0,\n",
              "  'world': 0.0,\n",
              "  'write': 0.0,\n",
              "  'written': 0.0},\n",
              " 'doc3': {'adapted': 0.0051861005947789396,\n",
              "  'afterwards': 0.0051861005947789396,\n",
              "  'antoine': 0.0,\n",
              "  'attribution': 0.0,\n",
              "  'avoiding': 0.0,\n",
              "  'based': 0.0,\n",
              "  'basics': 0.010372201189557879,\n",
              "  'begin': 0.0051861005947789396,\n",
              "  'bit': 0.0051861005947789396,\n",
              "  'check': 0.0,\n",
              "  'choosing': 0.0,\n",
              "  'class': 0.0,\n",
              "  'code': 0.0,\n",
              "  'coded': 0.0051861005947789396,\n",
              "  'coding': 0.0019140354245182742,\n",
              "  'colleagues': 0.0,\n",
              "  'come': 0.0051861005947789396,\n",
              "  'commons': 0.0,\n",
              "  'concepts': 0.0051861005947789396,\n",
              "  'conditions': 0.0051861005947789396,\n",
              "  'content': 0.0,\n",
              "  'course': 0.007656141698073097,\n",
              "  'covers': 0.0,\n",
              "  'cox': 0.0,\n",
              "  'created': 0.0,\n",
              "  'creative': 0.0,\n",
              "  'cut': 0.0051861005947789396,\n",
              "  'data': 0.0051861005947789396,\n",
              "  'days': 0.0,\n",
              "  'developers': 0.0,\n",
              "  'development': 0.0051861005947789396,\n",
              "  'difficulty': 0.0,\n",
              "  'director': 0.0,\n",
              "  'discuss': 0.0051861005947789396,\n",
              "  'dive': 0.0051861005947789396,\n",
              "  'easiest': 0.0051861005947789396,\n",
              "  'end': 0.0,\n",
              "  'engedu': 0.0,\n",
              "  'enjoy': 0.0,\n",
              "  'enlightened': 0.0,\n",
              "  'everything': 0.0051861005947789396,\n",
              "  'excited': 0.0051861005947789396,\n",
              "  'exercise': 0.0,\n",
              "  'exercises': 0.0,\n",
              "  'faster': 0.0051861005947789396,\n",
              "  'features': 0.0,\n",
              "  'file': 0.0051861005947789396,\n",
              "  'finish': 0.0051861005947789396,\n",
              "  'first': 0.0019140354245182742,\n",
              "  'free': 0.0,\n",
              "  'friendly': 0.0051861005947789396,\n",
              "  'fun': 0.0051861005947789396,\n",
              "  'functions': 0.0051861005947789396,\n",
              "  'future': 0.0,\n",
              "  'generosity': 0.0,\n",
              "  'get': 0.005742106273554823,\n",
              "  'getting': 0.0051861005947789396,\n",
              "  'glassman': 0.0,\n",
              "  'going': 0.0,\n",
              "  'good': 0.0,\n",
              "  'google': 0.0,\n",
              "  'great': 0.0051861005947789396,\n",
              "  'group': 0.0,\n",
              "  'help': 0.0,\n",
              "  'hope': 0.0051861005947789396,\n",
              "  'incentives': 0.0051861005947789396,\n",
              "  'includes': 0.0,\n",
              "  'installed': 0.0,\n",
              "  'intensive': 0.0,\n",
              "  'internet': 0.0,\n",
              "  'introducing': 0.0,\n",
              "  'introduction': 0.0,\n",
              "  'introductory': 0.0,\n",
              "  'john': 0.0,\n",
              "  'johnson': 0.0,\n",
              "  'keep': 0.0,\n",
              "  'know': 0.005742106273554823,\n",
              "  'language': 0.0019140354245182742,\n",
              "  'languages': 0.010372201189557879,\n",
              "  'large': 0.0051861005947789396,\n",
              "  'leading': 0.0,\n",
              "  'learning': 0.005742106273554823,\n",
              "  'lecture': 0.0,\n",
              "  'left': 0.0,\n",
              "  'let': 0.010372201189557879,\n",
              "  'license': 0.0,\n",
              "  'link': 0.0,\n",
              "  'linked': 0.0,\n",
              "  'loops': 0.0051861005947789396,\n",
              "  'machine': 0.0,\n",
              "  'maggie': 0.0,\n",
              "  'major': 0.0051861005947789396,\n",
              "  'makes': 0.0,\n",
              "  'manipulation': 0.0051861005947789396,\n",
              "  'material': 0.0,\n",
              "  'materials': 0.0,\n",
              "  'mentioned': 0.0,\n",
              "  'move': 0.0051861005947789396,\n",
              "  'much': 0.0019140354245182742,\n",
              "  'need': 0.015558301784336818,\n",
              "  'new': 0.0,\n",
              "  'newer': 0.0,\n",
              "  'news': 0.0,\n",
              "  'nick': 0.0,\n",
              "  'offered': 0.0,\n",
              "  'online': 0.0,\n",
              "  'organized': 0.0,\n",
              "  'overall': 0.0051861005947789396,\n",
              "  'page': 0.0,\n",
              "  'parallel': 0.0,\n",
              "  'parlante': 0.0,\n",
              "  'picard': 0.0,\n",
              "  'pick': 0.0,\n",
              "  'piotr': 0.0,\n",
              "  'place': 0.0051861005947789396,\n",
              "  'post': 0.0,\n",
              "  'pro': 0.0051861005947789396,\n",
              "  'programming': 0.0051861005947789396,\n",
              "  'projects': 0.0051861005947789396,\n",
              "  'put': 0.0,\n",
              "  'python': 0.0,\n",
              "  'quick': 0.010372201189557879,\n",
              "  'recognize': 0.0,\n",
              "  'recommend': 0.0,\n",
              "  'releases': 0.0,\n",
              "  'relevant': 0.0,\n",
              "  'right': 0.0051861005947789396,\n",
              "  'section': 0.0,\n",
              "  'sections': 0.0,\n",
              "  'set': 0.0,\n",
              "  'setup': 0.0,\n",
              "  'share': 0.0,\n",
              "  'small': 0.0051861005947789396,\n",
              "  'special': 0.0,\n",
              "  'started': 0.005742106273554823,\n",
              "  'starts': 0.0,\n",
              "  'steve': 0.0,\n",
              "  'strings': 0.0019140354245182742,\n",
              "  'thanks': 0.0,\n",
              "  'time': 0.020744402379115758,\n",
              "  'tried': 0.0,\n",
              "  'tutorial': 0.0,\n",
              "  'types': 0.0051861005947789396,\n",
              "  'universal': 0.0,\n",
              "  'use': 0.0051861005947789396,\n",
              "  'variables': 0.0051861005947789396,\n",
              "  'version': 0.0,\n",
              "  'videos': 0.0,\n",
              "  'waiting': 0.0051861005947789396,\n",
              "  'want': 0.0,\n",
              "  'way': 0.0051861005947789396,\n",
              "  'welcome': 0.0,\n",
              "  'whiz': 0.0051861005947789396,\n",
              "  'working': 0.0,\n",
              "  'world': 0.0051861005947789396,\n",
              "  'write': 0.0051861005947789396,\n",
              "  'written': 0.0}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq-1apmeXSBt"
      },
      "source": [
        "(b) Display the result in the panda data frame as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "4TY858e1XThD",
        "outputId": "3badb6e6-387e-4cd0-92a9-ef9bd22b8bc3"
      },
      "source": [
        "import pandas as pd\n",
        "tf_dataframe = pd.DataFrame(tfidf).transpose()\n",
        "tf_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>installed</th>\n",
              "      <th>avoiding</th>\n",
              "      <th>makes</th>\n",
              "      <th>director</th>\n",
              "      <th>starts</th>\n",
              "      <th>relevant</th>\n",
              "      <th>want</th>\n",
              "      <th>manipulation</th>\n",
              "      <th>language</th>\n",
              "      <th>get</th>\n",
              "      <th>content</th>\n",
              "      <th>friendly</th>\n",
              "      <th>leading</th>\n",
              "      <th>quick</th>\n",
              "      <th>post</th>\n",
              "      <th>section</th>\n",
              "      <th>parallel</th>\n",
              "      <th>hope</th>\n",
              "      <th>working</th>\n",
              "      <th>mentioned</th>\n",
              "      <th>help</th>\n",
              "      <th>videos</th>\n",
              "      <th>major</th>\n",
              "      <th>overall</th>\n",
              "      <th>begin</th>\n",
              "      <th>code</th>\n",
              "      <th>thanks</th>\n",
              "      <th>strings</th>\n",
              "      <th>let</th>\n",
              "      <th>adapted</th>\n",
              "      <th>faster</th>\n",
              "      <th>getting</th>\n",
              "      <th>license</th>\n",
              "      <th>universal</th>\n",
              "      <th>creative</th>\n",
              "      <th>going</th>\n",
              "      <th>functions</th>\n",
              "      <th>great</th>\n",
              "      <th>keep</th>\n",
              "      <th>organized</th>\n",
              "      <th>...</th>\n",
              "      <th>features</th>\n",
              "      <th>variables</th>\n",
              "      <th>data</th>\n",
              "      <th>nick</th>\n",
              "      <th>enlightened</th>\n",
              "      <th>course</th>\n",
              "      <th>coded</th>\n",
              "      <th>news</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>tried</th>\n",
              "      <th>use</th>\n",
              "      <th>small</th>\n",
              "      <th>created</th>\n",
              "      <th>enjoy</th>\n",
              "      <th>john</th>\n",
              "      <th>pick</th>\n",
              "      <th>page</th>\n",
              "      <th>easiest</th>\n",
              "      <th>glassman</th>\n",
              "      <th>cox</th>\n",
              "      <th>incentives</th>\n",
              "      <th>offered</th>\n",
              "      <th>generosity</th>\n",
              "      <th>materials</th>\n",
              "      <th>much</th>\n",
              "      <th>colleagues</th>\n",
              "      <th>waiting</th>\n",
              "      <th>large</th>\n",
              "      <th>recommend</th>\n",
              "      <th>languages</th>\n",
              "      <th>setup</th>\n",
              "      <th>discuss</th>\n",
              "      <th>introductory</th>\n",
              "      <th>right</th>\n",
              "      <th>know</th>\n",
              "      <th>file</th>\n",
              "      <th>developers</th>\n",
              "      <th>introduction</th>\n",
              "      <th>write</th>\n",
              "      <th>special</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc1</th>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.004048</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>0.004048</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007656</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows  157 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      installed  avoiding     makes  ...  introduction     write   special\n",
              "doc1   0.005484  0.000000  0.005484  ...      0.010968  0.000000  0.005484\n",
              "doc2   0.000000  0.009737  0.000000  ...      0.000000  0.000000  0.000000\n",
              "doc3   0.000000  0.000000  0.000000  ...      0.000000  0.005186  0.000000\n",
              "\n",
              "[3 rows x 157 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1qdC3Z4XUc-"
      },
      "source": [
        "3. Your reflection (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FndQ6FIqXhAo"
      },
      "source": [
        "Assume that your goal is to distinguish the differences between the three documents based on their features (term). So, we need to find a way to select the important feature (term) to reflect the difference between these three documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsC61WGlXjVr"
      },
      "source": [
        "(a) Take a look the content of three documents to understand. Then look at the term after tokenization. Do you think whether we should use POS to select good terms? In other words, do you think that using POS will help us to select a better term?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU8KyFXEHvLq"
      },
      "source": [
        "POS tagging helps us to understand which part of speech each word is.\n",
        "\n",
        "For example, if we dont identify the two different uses of the word like (a verb semantically charged with positive weight, as in I like you, and a neutral conjunction, as in I am like you) \n",
        "\n",
        "We will end up having many false positive results in the sentiment analysis.\n",
        "\n",
        "So yes, I think we should use POS to select good terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZEcS_lAXjbI"
      },
      "source": [
        "(b) Based on the content of the 3 document files above, do you suggest a better feature selection method? (use POS but choose other POS tags or a different method or combination of methods)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5N0xTXWHuo8"
      },
      "source": [
        "We can use Chi-square, Mutual information, Proportional difference and Information gain to help select words as features before classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgnR_VDrNFTO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}